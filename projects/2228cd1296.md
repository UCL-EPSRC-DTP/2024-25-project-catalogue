### Project Shield: Advancing Safe, Robust, and Aligned AI

Project ID: 2228cd1296
(You will need this ID for your application)

Research Theme: [Engineering](../themes/engineering.md)

UCL Lead department: [Electronic and Electrical Engineering (EEE)](../departments/electronic-and-electrical-engineering.md)

[Department Website](https://www.ucl.ac.uk/electronic-electrical-engineering)

Lead Supervisor: [Ilija Bogunovic](https://profiles.ucl.ac.uk/88270)

Project Summary:

The significance of AI safety and alignment cannot be overstated, given the expanding role of AI in our society and the associated potential risks. In the "Project Shield", you will collaborate with Dr. Ilija Bogunovic, Dr. Anna Maria Mandalari, Dr. Francesca Boem, and Dr. Laura Toni to pioneer innovative methods that ensure state-of-the-art AI models are robust and safe for the solution of engineering problems. Our primary objective is to address selected contemporary challenges in the realm of safe and robust AI:

- AI Alignment: Addressing a range of critical challenges â€“ Reinforcement Learning Reward Misspecification and Hacking, Goal Misgeneralization, Attack and Defenses for Large Language Models (LLMs), and Constitutional AI, and other key areas. (Supervisors: Dr. Ilija Bogunovic and Dr. Anna Maria Mandalari)

- IoT + cybersecurity: Enhancing IoT security by applying AI safety and alignment principles, mitigating potential risks in an interconnected world. (Supervisors: Dr. Anna Maria Mandalari and Dr. Francesca Boem)  

- Anomaly detection, learning and optimisation on graphs for reliable monitoring and control of dynamical network systems with applications including water networks, energy, social networks, epidemic models.  (Supervisors: Dr. Francesca Boem and Dr. Laura Toni)  

- Robustness in Reinforcement Learning: addressing various topics around reinforcement learning and online learning with the main goal of investigating credit assignment and explorations with the lens of robustness (Supervisors: Dr. Laura Toni and Dr Ilija Bogunovic)  

We seek ambitious candidates committed to advancing AI safety. The ideal candidate will demonstrate proficiency in safe AI, or anomaly detection and control algorithms, and exhibit practical experience in ML coding.

This project aligns with recent investments and initiatives (e.g., establishment of expert taskforces) aimed at assisting the UK in building the next generation of safe and aligned AI technologies. Join us in shaping the future of AI for the betterment of society.
